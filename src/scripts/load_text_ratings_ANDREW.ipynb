{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ba        ba.1   ba.2     ba.3  \\\n",
      "0   abv  appearance  aroma  beer_id   \n",
      "1  11.3         4.5    4.5      645   \n",
      "2   5.0         NaN    NaN    28191   \n",
      "3   5.0         3.5    3.5    57911   \n",
      "4   5.0         4.0    3.5    57913   \n",
      "\n",
      "                                            ba.4        ba.5  \\\n",
      "0                                      beer_name  brewery_id   \n",
      "1                        Trappistes Rochefort 10         207   \n",
      "2                             Myanmar Lager Beer        9369   \n",
      "3  Cantillon Tyrnilambic Baie D’Argousier Lambic         388   \n",
      "4              Cantillon Pikkulinnun Viskilambic         388   \n",
      "\n",
      "                             ba.6        ba.7     ba.8    ba.9  ...  \\\n",
      "0                    brewery_name        date  overall  palate  ...   \n",
      "1          Brasserie de Rochefort  1324810800      5.0     4.5  ...   \n",
      "2  Myanmar Brewery and Distillery  1322650800      NaN     NaN  ...   \n",
      "3             Brasserie Cantillon  1344074400      4.0     4.0  ...   \n",
      "4             Brasserie Cantillon  1344074400      4.0     4.0  ...   \n",
      "\n",
      "                             rb.6        rb.7     rb.8    rb.9   rb.10  \\\n",
      "0                    brewery_name        date  overall  palate  rating   \n",
      "1             Brasserie Rochefort  1387710000     19.0     4.0     4.6   \n",
      "2  Myanmar Brewery and Distillery  1322564400      6.0     2.0     1.7   \n",
      "3                       Cantillon  1353582000     17.0     4.0     4.1   \n",
      "4                       Cantillon  1416222000     16.0     4.0     4.1   \n",
      "\n",
      "                      rb.11  rb.12  \\\n",
      "0                     style  taste   \n",
      "1             Abt/Quadrupel    9.0   \n",
      "2                Pale Lager    4.0   \n",
      "3      Lambic Style - Fruit    8.0   \n",
      "4  Lambic Style - Unblended    9.0   \n",
      "\n",
      "                                               rb.13    rb.14        rb.15  \n",
      "0                                               text  user_id    user_name  \n",
      "1   a)  Geruch malzig-schwer-sÃ¼Ã. Riecht schon ...    83106     Erzengel  \n",
      "2  Can. Weak and watery, not the best beer of the...    91324  visionthing  \n",
      "3  Bottle @ One Pint Pub, Helsinki. Originally ra...    98624        tiong  \n",
      "4  Draught @Â Pikkulintu, Helsinki, Finland. A pr...    98624        tiong  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load in only the first N rows of the ratings dataset into a pandas dataframe\n",
    "N = 1000 # number of rows of data to read in\n",
    "fid = \"../../../MatchedBeerData/ratings.csv\"\n",
    "rawdata = pd.read_csv(fid, nrows=N)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(rawdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   abv appearance aroma beer_id  \\\n",
      "1  11.3        4.5   4.5     645   \n",
      "2   5.0        NaN   NaN   28191   \n",
      "3   5.0        3.5   3.5   57911   \n",
      "4   5.0        4.0   3.5   57913   \n",
      "5   6.0        4.0   4.0   81125   \n",
      "\n",
      "0                                      beer_name brewery_id  \\\n",
      "1                        Trappistes Rochefort 10        207   \n",
      "2                             Myanmar Lager Beer       9369   \n",
      "3  Cantillon Tyrnilambic Baie D’Argousier Lambic        388   \n",
      "4              Cantillon Pikkulinnun Viskilambic        388   \n",
      "5     Drie Fonteinen Oude Geuze - Armand & Tommy       2216   \n",
      "\n",
      "0                    brewery_name        date overall palate  ...  \\\n",
      "1          Brasserie de Rochefort  1324810800     5.0    4.5  ...   \n",
      "2  Myanmar Brewery and Distillery  1322650800     NaN    NaN  ...   \n",
      "3             Brasserie Cantillon  1344074400     4.0    4.0  ...   \n",
      "4             Brasserie Cantillon  1344074400     4.0    4.0  ...   \n",
      "5           Brouwerij 3 Fonteinen  1346234400     4.0    4.0  ...   \n",
      "\n",
      "0                    brewery_name        date overall palate rating  \\\n",
      "1             Brasserie Rochefort  1387710000    19.0    4.0    4.6   \n",
      "2  Myanmar Brewery and Distillery  1322564400     6.0    2.0    1.7   \n",
      "3                       Cantillon  1353582000    17.0    4.0    4.1   \n",
      "4                       Cantillon  1416222000    16.0    4.0    4.1   \n",
      "5           Brouwerij 3 Fonteinen  1345284000    16.0    4.0    4.0   \n",
      "\n",
      "0                     style taste  \\\n",
      "1             Abt/Quadrupel   9.0   \n",
      "2                Pale Lager   4.0   \n",
      "3      Lambic Style - Fruit   8.0   \n",
      "4  Lambic Style - Unblended   9.0   \n",
      "5     Lambic Style - Gueuze   8.0   \n",
      "\n",
      "0                                               text user_id    user_name  \n",
      "1   a)  Geruch malzig-schwer-sÃ¼Ã. Riecht schon ...   83106     Erzengel  \n",
      "2  Can. Weak and watery, not the best beer of the...   91324  visionthing  \n",
      "3  Bottle @ One Pint Pub, Helsinki. Originally ra...   98624        tiong  \n",
      "4  Draught @Â Pikkulintu, Helsinki, Finland. A pr...   98624        tiong  \n",
      "5  750ml bottleBottling date: 2011/02/17 - Pours ...   98624        tiong  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get rid of the first row and make the second row the header\n",
    "rawdata.columns = rawdata.iloc[0]\n",
    "data = rawdata[1:]\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                               text  \\\n",
      "1  Best before 27.07.2016Directly reviewed in com...   \n",
      "3  Bottle @ One Pint Pub, Helsinki. 2006 vintage....   \n",
      "4  Originally rated on 16.11.2009, draught @ Pikk...   \n",
      "5  750ml bottle, originally rated on 18.8.2012.Bo...   \n",
      "6  375ml bottle @ Pikkulintu, Helsinki. Originall...   \n",
      "\n",
      "0                                               text  \n",
      "1   a)  Geruch malzig-schwer-sÃ¼Ã. Riecht schon ...  \n",
      "3  Bottle @ One Pint Pub, Helsinki. Originally ra...  \n",
      "4  Draught @Â Pikkulintu, Helsinki, Finland. A pr...  \n",
      "5  750ml bottleBottling date: 2011/02/17 - Pours ...  \n",
      "6  375ml bottle @ Pikkulintu, HelsinkiPours orang...  \n"
     ]
    }
   ],
   "source": [
    "# Get rid of all rows with NaN values for the 'text' column\n",
    "COLS_TO_DROP_NANS_FROM = [\"text\"] # Add more columns to this list if you want to drop rows with NaNs in any of those columns\n",
    "\n",
    "for column_name in COLS_TO_DROP_NANS_FROM:\n",
    "    data = data.dropna(subset=column_name)\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data[\"text\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Strategies for Sentiment Analysis:\n",
    "- Rule Based:\n",
    "    - Use lexicons (words/phrases as tokens) to signal GOOD and BAD \n",
    "    - Does not pick up on sarcasm, negation, or idiomatic phrases\n",
    "- Machine Learning:\n",
    "    - Naive Bayes (Classification)\n",
    "        - Possibly the best option for understanding sentiment based on word occurances.\n",
    "        - Calculates the likelyhood that a new review is + or - based on previous scored reviews.\n",
    "        - Good on smaller datasets and text data (need to lok into this)\n",
    "    - Logistic Regression\n",
    "        - Gives the probability of a binary outcome (GOOD or BAD) but also gives plenty of interpretability through coefficients.\n",
    "        - Good on large datasets (may overfit without a large dataset)\n",
    "\n",
    "__Goal__: Understand if words like \"fruity\" \"hoppy\" or \"bitter\" are associated positivly, negativly, or neutral to understand what makes a beer love, hated, polarizing, or neutral. Then we can compare these words accross regions/countries/climates to see how geographical context affects beer tastes. Some deliverables can include word clouds for the first part and heat maps for the second part relating geography to beers with certain descriptors.\n",
    "\n",
    "__Possible Pipeline__:\n",
    "- __Preprocess the reviews__: Before using the reviews for training, it’s essential to preprocess them to remove noise and standardize the text. Here are the common preprocessing steps:\n",
    "    - __Convert to lowercase__: Convert all the reviews to lowercase letters. This step ensures that the model treats words with different cases as the same.\n",
    "    - __Remove punctuation__: Remove any punctuation marks or special characters from the reviews. Punctuation does not contribute much to sentiment analysis and can be safely removed.\n",
    "    - __Remove stopwords__: Stopwords are common words such as “the,” “is,” “and,” etc., which do not carry much sentiment. Remove these words from the reviews as they can introduce noise to the model.\n",
    "    - __Stemming or lemmatization__: Perform stemming or lemmatization to reduce words to their base form. Stemming reduces a word to its root form by removing suffixes, while lemmatization brings words to their dictionary form. This step helps reduce the number of unique words and improves the model’s performance.\n",
    "    - __Tokenization__: Split the sentences into individual words. This allows you to analyze each word separately and build the word count table later.\n",
    "    \n",
    "- __Split the Reviews by Category__:\n",
    "    - 1–3 stars: Negative sentiment\n",
    "    - 4–6 stars: Neutral sentiment\n",
    "    - 7–10 stars: Positive sentiment\n",
    "\n",
    "- __Visualization of Key Words__:\n",
    "    - Use word clouds and/or frequency plots to show what are the most likely words and phrases used for positive and negative scores in particular countries.\n",
    "\n",
    "- __Topic Identification and Distribution__: (Machine Learning)\n",
    "    - Use Latent Dirichlet Allocation (LDA) to group keywords into topics (ex. Fruity flavor profile, Malty and sweet flavors, Bitter or hoppy profile, Light and smooth texture, Sour or tart flavors). We can then use these topics and their associated keywords and scores to identify what kinds of flavor profiles are most common, most like, most hated, etc. in each region.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Naive Bayes implementation from : https://www.geeksforgeeks.org/naive-bayes-vs-logistic-regression-in-machine-learning/\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using both models\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions))\n",
    "print(\"\\nNaive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
